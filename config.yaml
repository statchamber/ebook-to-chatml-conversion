# you don't even need to change most of these settings besides API, Summarization, and Chunk.
# then just put your books in ./ebooks/ and run the script.

api:
  kobold:
    enabled: true
    url: "http://localhost:5001/api/"
  openai:
    enabled: false
    api_key: "" # Your OpenAI API key
    api_base: "" # Your OpenAI API base URL (optional)
    model: "gpt-3.5-turbo" # Specify the OpenAI model to use (For conversion)
  gemini:
    enabled: false
    api_key: "" # Your Gemini API key
    model: "gemini-1.5-flash" # Specify the Gemini model to use (For conversion)
    max_retries: 3 # Maximum number of retries

summarization:
  summarize_every: 20  # Summarize every x lines (multiple of 5, maximum = chunk.context)
  api:
    kobold:
      enabled: true
    openai:
      enabled: false
    gemini:
      enabled: false

chunk:
  context: 20 # Lines to add for context at the start and end of each chunk (multiple of 5)
  max_convert: 20 # Max lines to convert (multiple of 5, use 1000000 for whole book)
  max_retries: 3 # Maximum number of retries for converting chunk

character:
  narrator: true # Include narrator in character list
  unknown: true # Include unknown in character list
  # Custom character names can be added here (ex: Ruby: true, firstname_lastname: true, y/n: true)
  # Only add names the AI doesn't automatically detect
  # Adding custom names may not guarantee the use by the AI

output:
  regular: true # Regular readable format
  chatml: true # ChatML format
  technical: true # A json file with the technical details of the conversion, contaning summaries, actions, speakers, etc.

entity_detection:
  model: "flair/ner-english-large" # Use "flair/ner-english-large" for better performance but higher resource usage. Use "flair/ner-english-fast" for the opposite
  confidence: 0.9 # Lower: more false detections; Higher: might miss characters (for "ner-english-large" use 0.9, for "ner-english-fast" use 0.5)
  reset_every: 20 # Reset the tagger every x chunks (Prevent memory leaks)

other:
  debug: false # Enable debug mode
  concurrent_stories: 1 # Number of stories to convert at a time (Higher values require more system resources)
  string_similarity: 0.6 # String similarity threshold for detecting the same character
